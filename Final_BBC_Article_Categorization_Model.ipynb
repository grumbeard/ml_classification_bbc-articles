{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final BBC Article Categorization Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnUjtdvmSlRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4952ef9a-4594-4bdb-9e58-2c7f7bc320bc"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6bEQDs_So20"
      },
      "source": [
        "# BBC Article Categorization Model\n",
        "\n",
        "using data from https://www.kaggle.com/yufengdev/bbc-fulltext-and-category\n",
        "\n",
        "**Goal: Train model to predict category [sport/business/politics/tech/entertainment] of BBC article, given article text.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5ZG2CoCTjok"
      },
      "source": [
        "## Import Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ui-GLi96Ss4T",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "13c30c8e-93a2-4146-baa1-8296a1755cd2"
      },
      "source": [
        "# Upload kaggle.json file\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-945ae113-9f15-4ef8-aa5a-3d844ecb0319\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-945ae113-9f15-4ef8-aa5a-3d844ecb0319\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HrmwigyFUtBW"
      },
      "source": [
        "# Import dependencies for downloading datasets from Kaggle platform\n",
        "! git clone https://github.com/mdda/colab_helper\n",
        "from colab_helper import utils as chu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRiugwNPTeCu"
      },
      "source": [
        "! pip install kaggle\n",
        "chu.kaggle_credentials(file='./kaggle.json')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDcFFnTQTsQP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "2af565f7-582e-43df-f865-82543f960104"
      },
      "source": [
        "# Import BBC article dataset from Kaggle platform\n",
        "## Description page : https://www.kaggle.com/yufengdev/bbc-fulltext-and-category\n",
        "! kaggle datasets download -d yufengdev/bbc-fulltext-and-category\n",
        "print('Dataset downloaded')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading bbc-fulltext-and-category.zip to /content\n",
            "\r  0% 0.00/1.83M [00:00<?, ?B/s]\n",
            "\r100% 1.83M/1.83M [00:00<00:00, 60.5MB/s]\n",
            "Dataset downloaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czFAQZKeWLa-"
      },
      "source": [
        "## Unzip Data and Split into Train / Test DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKyxW2GMW4rz"
      },
      "source": [
        "! unzip -qq bbc-fulltext-and-category.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOhCu8tJXLYk"
      },
      "source": [
        "! rm -r bbc-fulltext-and-category.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GceEQPNeXNXQ"
      },
      "source": [
        "import pandas as pd\n",
        "ds = pd.read_csv('bbc-text.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXaaVnsHq34M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6d6d88e-ee80-41ec-c3bf-db57867e90a3"
      },
      "source": [
        "!wget -qq https://www.dropbox.com/s/v14xhvjmfniraf3/glove6b100dtxt.zip\n",
        "# !wget -qq http://nlp.stanford.edu/data/glove.6B.zip\n",
        "  \n",
        "!unzip glove6b100dtxt.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  glove6b100dtxt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZYyHVvkcjZP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "3abdc71b-eae3-4c27-9c9b-eca81391ae5a"
      },
      "source": [
        "ds.category.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bNv94fas10fC"
      },
      "source": [
        "ds['category'] = pd.Categorical(ds['category'])\n",
        "ds['category'] = ds.category.cat.codes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VGHLOeMqu4G",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "35fbbe02-d650-4da6-e1a7-fa740d5d7b11"
      },
      "source": [
        "# Split data by category and distribute randomly into test / train dataframes (10:90)\n",
        "import math\n",
        "from sklearn.utils import shuffle\n",
        "\n",
        "train_data = pd.DataFrame()\n",
        "test_data = pd.DataFrame()\n",
        "\n",
        "for i in ds.category.unique():\n",
        "  category_data = ds[ds.category == i]\n",
        "  # print(category_data.head())\n",
        "  new_category_data = shuffle(category_data, random_state = 0)\n",
        "  train_data = pd.concat([train_data, new_category_data.iloc[:math.floor(category_data.text.size * 0.9)]])\n",
        "  test_data = pd.concat([test_data, new_category_data.iloc[math.ceil(category_data.text.size * 0.9):]])\n",
        "\n",
        "print(train_data.head())\n",
        "print(test_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      category                                               text\n",
            "1146         4  bbc leads interactive bafta wins the bbc and t...\n",
            "1828         4  go-ahead for new internet names the internet c...\n",
            "402          4  warnings about junk mail deluge the amount of ...\n",
            "512          4  digital guru floats sub-$100 pc nicholas negro...\n",
            "446          4  broadband challenges tv viewing the number of ...\n",
            "      category                                               text\n",
            "1634         4  sony psp handheld console hits us the latest h...\n",
            "2074         4  apple sues  tiger  file sharers apple has take...\n",
            "859          4  finding new homes for old phones re-using old ...\n",
            "1605         4  sony psp console hits us in march us gamers wi...\n",
            "2103         4  ds aims to touch gamers the mobile gaming indu...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcJjUS2289ci"
      },
      "source": [
        "## Separate Prediction Target from Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAl8vKpe3ZuM"
      },
      "source": [
        "train_target = train_data.pop('category')\n",
        "test_target = test_data.pop('category')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jG6nETLP9DW1"
      },
      "source": [
        "## Tokenize Training Data (Article Text)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSG2h_4Zk7YZ"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from tensorflow.keras.layers import Dense, Input, GlobalMaxPooling1D, LSTM\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Embedding, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import Constant"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0XJyHby9348",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "f917e9d9-d0bd-41ce-f3f5-bce46299a045"
      },
      "source": [
        "# Preview data in Train DataFrame\n",
        "train_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1146</th>\n",
              "      <td>bbc leads interactive bafta wins the bbc and t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1828</th>\n",
              "      <td>go-ahead for new internet names the internet c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>warnings about junk mail deluge the amount of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>digital guru floats sub-$100 pc nicholas negro...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>broadband challenges tv viewing the number of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   text\n",
              "1146  bbc leads interactive bafta wins the bbc and t...\n",
              "1828  go-ahead for new internet names the internet c...\n",
              "402   warnings about junk mail deluge the amount of ...\n",
              "512   digital guru floats sub-$100 pc nicholas negro...\n",
              "446   broadband challenges tv viewing the number of ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeAatC2I9aAL"
      },
      "source": [
        "# Take each row of train text and append to train_text_list\n",
        "train_text_list = []\n",
        "for i in train_data.text:\n",
        "  train_text_list.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xT8NKAqcG-lZ"
      },
      "source": [
        "# Take each row of test text and append to test_text_list\n",
        "test_text_list = []\n",
        "for i in test_data.text:\n",
        "  test_text_list.append(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGboKJHBpfA4"
      },
      "source": [
        "# Init Tokenizer\n",
        "MAX_SEQUENCE_LENGTH = 5000\n",
        "MAX_NUM_WORDS = 20000\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqbHCiOP15oF",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5c34f99-25e7-43c1-9199-2fb75acd6d93"
      },
      "source": [
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(train_text_list)\n",
        "train_sequences = tokenizer.texts_to_sequences(train_text_list)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_text_list)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28667 unique tokens.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzeqSGji2ErR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "75fdfa00-537b-41e4-fc67-86e14da1372e"
      },
      "source": [
        "# Preview first sequence\n",
        "train_sequences[0][:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[110,\n",
              " 2957,\n",
              " 2025,\n",
              " 2680,\n",
              " 1154,\n",
              " 1,\n",
              " 110,\n",
              " 4,\n",
              " 1,\n",
              " 313,\n",
              " 1267,\n",
              " 20,\n",
              " 625,\n",
              " 1,\n",
              " 1164,\n",
              " 21,\n",
              " 33,\n",
              " 41,\n",
              " 7,\n",
              " 2025]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQr6KugD2QvA"
      },
      "source": [
        "# Prepare Training dataset\n",
        "X_train = pad_sequences(train_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nf6LzxHjHZyh"
      },
      "source": [
        "# Prepare Test dataset\n",
        "X_val = pad_sequences(test_sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kcFgtBoH2T0w"
      },
      "source": [
        "# Prepare Training Target dataset\n",
        "## Take each row of category values and append to train_target_list\n",
        "train_target_list = []\n",
        "for i in train_target:\n",
        "  train_target_list.append(i)\n",
        "\n",
        "y_train = to_categorical(np.asarray(train_target_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n1sOiEIIUog"
      },
      "source": [
        "# Prepare Test Target dataset\n",
        "## Take each row of category values and append to test_target_list\n",
        "test_target_list = []\n",
        "for i in test_target:\n",
        "  test_target_list.append(i)\n",
        "\n",
        "y_val = to_categorical(np.asarray(test_target_list))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BIlj_D5lIU42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "f1ad5eef-2d6f-49b4-e696-98b681fc4b99"
      },
      "source": [
        "print('Shape of train data tensor:', X_train.shape)\n",
        "print('Shape of label tensor:', y_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of train data tensor: (2000, 5000)\n",
            "Shape of label tensor: (2000, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5DBxxHxnDT6j"
      },
      "source": [
        "## Prepare Embedding Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8QSspI7p5yo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3c1fa013-e511-4670-95bf-59cecd744a76"
      },
      "source": [
        "# Use word embeddings index from pre-trained GloVe\n",
        "print('Indexing word vectors.')\n",
        "\n",
        "BASE_DIR = ''\n",
        "GLOVE_DIR = os.path.join(BASE_DIR, '')\n",
        "\n",
        "embeddings_index = {}\n",
        "with open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt')) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Indexing word vectors.\n",
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asqIYv1xDhd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "84711bfb-6288-43e3-f3bc-f5d019223bee"
      },
      "source": [
        "print('Preparing embedding matrix.')\n",
        "\n",
        "# Prepare embedding matrix\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "# load pre-trained word embeddings into an Embedding layer\n",
        "# note that we set trainable = False so as to keep the embeddings fixed\n",
        "embedding_layer = Embedding(num_words,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=MAX_SEQUENCE_LENGTH,\n",
        "                            trainable=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing embedding matrix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlo1hPHmqBmg"
      },
      "source": [
        "## Test GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wILHHc4PqFjr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "1351d720-c98b-4ef7-d6f5-932f36137ee8"
      },
      "source": [
        "embeddings_index['news']"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-0.66842  , -0.41713  ,  0.42473  , -0.9329   , -0.36823  ,\n",
              "       -0.26647  , -0.10715  ,  0.093359 ,  0.25288  , -0.42413  ,\n",
              "        0.67356  ,  0.092664 ,  0.43201  , -0.25714  , -0.11222  ,\n",
              "        0.059157 ,  0.33147  , -1.2479   , -0.35577  , -0.21875  ,\n",
              "       -0.22346  ,  0.10209  , -0.4843   ,  0.7824   ,  0.3118   ,\n",
              "       -0.083924 ,  0.56489  ,  0.98637  , -0.12308  ,  0.92539  ,\n",
              "        0.28811  ,  0.4003   , -0.64225  ,  0.12647  , -0.27778  ,\n",
              "        0.045568 , -0.18598  , -0.15247  , -0.42322  ,  0.29807  ,\n",
              "       -0.68476  , -0.11121  , -1.1391   ,  0.072205 , -0.038877 ,\n",
              "       -0.54775  , -0.0032873, -0.85587  ,  0.3267   , -0.79493  ,\n",
              "        0.33434  ,  0.29464  ,  0.44074  ,  0.69114  , -0.10615  ,\n",
              "       -2.5303   , -0.5923   ,  0.4648   ,  2.2093   ,  0.77166  ,\n",
              "       -0.60216  ,  0.46264  , -0.70728  , -1.1414   ,  0.40916  ,\n",
              "       -0.31745  ,  0.41431  ,  0.49908  ,  0.49434  ,  1.0044   ,\n",
              "       -0.37273  , -0.16246  ,  0.23608  , -0.71456  ,  0.53312  ,\n",
              "        0.4593   ,  0.19464  ,  0.23521  , -1.5447   , -0.56067  ,\n",
              "        0.37415  , -0.54415  ,  0.40648  , -0.19946  , -0.83036  ,\n",
              "       -1.1934   , -0.53713  ,  0.43504  ,  0.072245 , -0.85625  ,\n",
              "        1.2625   , -0.048436 ,  0.1157   , -0.013286 , -1.1952   ,\n",
              "        0.3724   ,  0.63674  , -0.51084  ,  0.99947  ,  1.01     ],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJS_rECIFPRP"
      },
      "source": [
        "## Define Model and Compile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoDDawqUDPsQ"
      },
      "source": [
        "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "x = LSTM(128)(embedded_sequences)\n",
        "x = Dropout(0.3)(x)\n",
        "preds = Dense(len(ds.category.unique()), activation='softmax')(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQZEGJrwFuzI"
      },
      "source": [
        "model = Model(sequence_input, preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0TybQ7KFxBe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "2c017cb4-8051-4453-d112-5f1ccedaa1c3"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 5000)]            0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 5000, 100)         2000100   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               117248    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 5)                 645       \n",
            "=================================================================\n",
            "Total params: 2,117,993\n",
            "Trainable params: 117,893\n",
            "Non-trainable params: 2,000,100\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTTnvJW8F7R5"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='rmsprop',\n",
        "              metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mDN1Ps7F79e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "outputId": "d617cd01-79e6-4b16-faa8-1c7b89945654"
      },
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=128,\n",
        "          epochs=10,\n",
        "          validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2000 samples, validate on 221 samples\n",
            "Epoch 1/10\n",
            "2000/2000 [==============================] - 419s 210ms/sample - loss: 1.4156 - acc: 0.4420 - val_loss: 1.1338 - val_acc: 0.6244\n",
            "Epoch 2/10\n",
            "2000/2000 [==============================] - 385s 192ms/sample - loss: 0.9182 - acc: 0.6885 - val_loss: 0.7843 - val_acc: 0.7059\n",
            "Epoch 3/10\n",
            "2000/2000 [==============================] - 369s 185ms/sample - loss: 0.9705 - acc: 0.6960 - val_loss: 0.4655 - val_acc: 0.8643\n",
            "Epoch 4/10\n",
            "2000/2000 [==============================] - 360s 180ms/sample - loss: 0.5508 - acc: 0.8260 - val_loss: 0.9766 - val_acc: 0.6787\n",
            "Epoch 5/10\n",
            "2000/2000 [==============================] - 347s 173ms/sample - loss: 0.5814 - acc: 0.8265 - val_loss: 0.3779 - val_acc: 0.9005\n",
            "Epoch 6/10\n",
            "2000/2000 [==============================] - 364s 182ms/sample - loss: 0.6396 - acc: 0.8095 - val_loss: 0.6309 - val_acc: 0.8009\n",
            "Epoch 7/10\n",
            "2000/2000 [==============================] - 356s 178ms/sample - loss: 0.4269 - acc: 0.8910 - val_loss: 0.3002 - val_acc: 0.9095\n",
            "Epoch 8/10\n",
            "2000/2000 [==============================] - 365s 182ms/sample - loss: 0.4136 - acc: 0.8880 - val_loss: 0.2985 - val_acc: 0.9276\n",
            "Epoch 9/10\n",
            "2000/2000 [==============================] - 363s 182ms/sample - loss: 0.5288 - acc: 0.8350 - val_loss: 0.3100 - val_acc: 0.9050\n",
            "Epoch 10/10\n",
            "2000/2000 [==============================] - 385s 193ms/sample - loss: 0.5399 - acc: 0.8485 - val_loss: 0.3560 - val_acc: 0.9140\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fd42c028048>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}